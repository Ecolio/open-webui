{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities identified in the document:\n",
      "\n",
      "GPE (Countries):\n",
      "1. South Korea\n",
      "2. United States\n",
      "3. United Kingdom\n",
      "4. Canada\n",
      "5. Australia\n",
      "6. Singapore\n",
      "7. France\n",
      "8. Japan\n",
      "9. Germany\n",
      "10. Belgium\n",
      "11. Finland\n",
      "12. New Zealand\n",
      "13. Poland\n",
      "14. Slovenia\n",
      "15. India\n",
      "\n",
      "PERSON:\n",
      "1. Andrea Renda\n",
      "2. Matthew Linares\n",
      "3. Alan F\n",
      "4. Peter Cihon\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import spacy\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import geotext\n",
    "\n",
    "# Load a more comprehensive NER model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Load the PDF and extract text\n",
    "loader = PyPDFLoader(\"/Users/lijou/Documents/Documents/AI litterature/EU/EU_AI.pdf\")\n",
    "pages = loader.load()\n",
    "pdf_text = '\\n'.join([page.page_content for page in pages])\n",
    "# Remove newline characters and extra white space\n",
    "pdf_text = re.sub('\\s+', ' ', pdf_text)\n",
    "\n",
    "# Apply NER to the extracted text\n",
    "doc = nlp(pdf_text)\n",
    "entities = defaultdict(list)\n",
    "\n",
    "# Use GeoText for better place name recognition\n",
    "geo_text = geotext.GeoText(pdf_text)\n",
    "\n",
    "# Filter entities and remove duplicates\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"GPE\":\n",
    "        entities[ent.label_].append(ent.text)\n",
    "    elif ent.label_ == \"PERSON\":\n",
    "        # Use a regular expression to filter out invalid names\n",
    "        if re.match(r\"^[A-Z][a-z]* [A-Z][a-z]*$\", ent.text):\n",
    "            entities[ent.label_].append(ent.text)\n",
    "\n",
    "# Adding GeoText results to GPE\n",
    "entities[\"GPE\"].extend(geo_text.countries)\n",
    "\n",
    "# Remove duplicates by converting lists to sets\n",
    "entities = {key: list(set(values)) for key, values in entities.items()}\n",
    "\n",
    "# Create system message with structured format\n",
    "system_message = f\"Use the following document to answer the question. Here are the entities identified in the text:\\nGPE (Countries): {', '.join(entities['GPE'])}\\nPERSON (People): {', '.join(entities['PERSON'])}\\nList all the countries and people named in the document.\"\n",
    "\n",
    "question = 'List all the GPE and PERSON in this document'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': question},\n",
    "]\n",
    "\n",
    "response = ollama.chat(model='llama3-gradient', messages=messages)\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GPE': ['South Korea', 'Bristol', 'Poland', 'Belgium', 'Finland', 'India', 'some Member States', 'ri', 'Singapore', 'New Zealand', 'Japan', 'the United States', 'France', 'AI', 'US', 'Slovenia', 'proach', 'China', 'behavio', 'United States', 'Australia', 'Canada', 'Germany', 'Biometr ics', 'UK', 'United Kingdom'], 'PERSON': ['Andrea Renda', 'Standardisation Standardi', 'Mihalis Kritikos', 'Peter Cihon', 'Matthew Linares', 'Alan F']}\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
